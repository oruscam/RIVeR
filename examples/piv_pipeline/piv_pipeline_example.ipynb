{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447acb83",
   "metadata": {},
   "source": [
    "## PIV Pipeline example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a57c8f-fca9-40ff-a0c9-67ad7fbab8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import river.core.define_roi_masks as drm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b8a91a-d4c7-43d2-aab2-f8ae47965fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "image_1_path = Path('0000000001.jpg')\n",
    "image_2_path = Path('0000000003.jpg')\n",
    "\n",
    "image_1 = cv2.imread(image_1_path)\n",
    "image_2 = cv2.imread(image_2_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "882416b4-6554-4a21-aef2-7303270d245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uav_matrix = json.loads(Path('uav_transformation_matrix.json').read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7d7e757-dae5-4ec9-940d-84ddafe9c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsections = json.loads(Path('xsections.json').read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30bf2a13-95b7-4d7d-9baf-f79bbb9a906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_roi = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25f96c18-f3ae-438c-9f94-cf6cfaa4cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, bbox = drm.create_mask_and_bbox(image_1, xsections, uav_matrix, height_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0bd23f-bff0-4a90-b2ec-bb4c101eeaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bbox.json', 'w') as file:\n",
    "    file.write(json.dumps(bbox))\n",
    "with open('mask.json', 'w') as file:\n",
    "    file.write(json.dumps(mask.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9502bc7-8f14-40ee-8fdb-26b4bf63b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.core.piv_pipeline import run_test\n",
    "\n",
    "results = run_test(image_1_path, image_2_path, mask, bbox, filter_sub_background=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4465bd0-8161-4f19-b371-f02fa668e352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 31 frames...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpiv_pipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_analyze_all\n\u001b[1;32m      3\u001b[0m images_location \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframes/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_analyze_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_sub_background\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/RIVeR/river/core/piv_pipeline.py:203\u001b[0m, in \u001b[0;36mrun_analyze_all\u001b[0;34m(images_location, mask, bbox, interrogation_area_1, interrogation_area_2, mask_auto, multipass, standard_filter, standard_threshold, median_test_filter, epsilon, threshold, step, filter_grayscale, filter_clahe, clip_limit_clahe, filter_sub_background, save_background, workdir)\u001b[0m\n\u001b[1;32m    200\u001b[0m \tbbox \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, width, height]\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Process a test pair to get expected dimensions\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m test_result \u001b[38;5;241m=\u001b[39m \u001b[43mpiv_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m\t\u001b[49m\u001b[43minterrogation_area_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m\t\u001b[49m\u001b[43minterrogation_area_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mmask_auto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mmultipass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mstandard_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mstandard_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mmedian_test_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mfilter_grayscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mfilter_clahe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mclip_limit_clahe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mfilter_sub_background\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m expected_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Calculate chunks and pairs\u001b[39;00m\n",
      "File \u001b[0;32m~/git/RIVeR/river/core/piv_loop.py:56\u001b[0m, in \u001b[0;36mpiv_loop\u001b[0;34m(path_images, mask, bbox, interrogation_area_1, interrogation_area_2, mask_auto, multipass, standard_filter, standard_threshold, median_test_filter, epsilon, threshold, step, filter_grayscale, filter_clahe, clip_limit_clahe, filter_sub_background, background, start, end)\u001b[0m\n\u001b[1;32m     53\u001b[0m mask_piv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones_like(mask, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fr \u001b[38;5;241m<\u001b[39m last_fr:\n\u001b[0;32m---> 56\u001b[0m \timage1 \u001b[38;5;241m=\u001b[39m \u001b[43mimpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mpath_images\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_grayscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_clahe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_limit_clahe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_sub_background\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \timage2 \u001b[38;5;241m=\u001b[39m impp\u001b[38;5;241m.\u001b[39mpreprocess_image(\n\u001b[1;32m     60\u001b[0m \t\tpath_images[fr \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], filter_grayscale, filter_clahe, clip_limit_clahe, filter_sub_background, background\n\u001b[1;32m     61\u001b[0m \t)\n\u001b[1;32m     63\u001b[0m \txtable, ytable, utable, vtable, typevector, gradient \u001b[38;5;241m=\u001b[39m piv_fftmulti(\n\u001b[1;32m     64\u001b[0m \t\timage1,\n\u001b[1;32m     65\u001b[0m \t\timage2,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \t\tstep\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m     78\u001b[0m \t)\n",
      "File \u001b[0;32m~/git/RIVeR/river/core/image_preprocessing.py:25\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image, filt_grayscale, filt_clahe, clip_limit_clahe, filt_sub_background, background)\u001b[0m\n\u001b[1;32m     22\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE) \u001b[38;5;28;01mif\u001b[39;00m filt_grayscale \u001b[38;5;28;01melse\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mimread(image)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filt_sub_background \u001b[38;5;129;01mand\u001b[39;00m filt_grayscale:\n\u001b[0;32m---> 25\u001b[0m \timage \u001b[38;5;241m=\u001b[39m \u001b[43msubtract_background\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filt_clahe \u001b[38;5;129;01mand\u001b[39;00m filt_grayscale:\n\u001b[1;32m     28\u001b[0m \tclahe \u001b[38;5;241m=\u001b[39m create_clahe(clip_limit_clahe)\n",
      "File \u001b[0;32m~/git/RIVeR/river/core/image_preprocessing.py:95\u001b[0m, in \u001b[0;36msubtract_background\u001b[0;34m(grayscale_image, average_image)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubtract_background\u001b[39m(grayscale_image, average_image):\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m\t\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\tSubtract the background from a grayscale image using the average image.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m\t    The background-subtracted image.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m\t\"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \tsubtracted_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrayscale_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \tsubtracted_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(subtracted_image, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m     97\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m subtracted_image\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "from river.core.piv_pipeline import run_analyze_all\n",
    "\n",
    "images_location = Path('frames/')\n",
    "results = run_analyze_all(images_location, mask=mask, bbox=bbox, filter_sub_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a4c0260-ae8a-4aeb-8285-41f95eb1741a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'u_median'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m ytable \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#Calculte the median velocity field\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m u_median \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mu_median\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mreshape(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m v_median \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv_median\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Calculte the velocity field #75\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'u_median'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xtable = np.array(results['x']).reshape(results['shape'])\n",
    "ytable = np.array(results['y']).reshape(results['shape'])\n",
    "#Calculte the median velocity field\n",
    "u_median = np.array(results['u_median']).reshape(results['shape'])\n",
    "v_median = np.array(results['v_median']).reshape(results['shape'])\n",
    "#Calculte the velocity field #75\n",
    "u_75 = np.array(results['u'][20]).reshape(results['shape'])\n",
    "v_75 = np.array(results['v'][20]).reshape(results['shape'])\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(cv2.imread(image_1_path, cv2.IMREAD_GRAYSCALE))\n",
    "ax.imshow(mask, alpha=0.2,cmap='grey')\n",
    "ax.quiver(xtable, ytable, u_median, -v_median, color='red')\n",
    "ax.quiver(xtable, ytable, u_75, -v_75, color='green')\n",
    "ax.quiver(xtable, ytable, u_75, -v_75, color='green')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "river",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
